{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Pw7f2ghccuoK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from pathlib import Path\n",
        "from tokenizers import Tokenizer\n",
        "from huggingface_hub import PyTorchModelHubMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twgsNOvPiDFt",
        "outputId": "7d6306b1-7ed5-4b2d-c764-d644819bdfc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "GPU Name: NVIDIA A100-SXM4-40GB\n",
            "Tensor on GPU: tensor([1., 2., 3.], device='cuda:0')\n",
            "Result of operation on GPU: tensor([2., 4., 6.], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(f\"CUDA available: {cuda_available}\")\n",
        "\n",
        "# If CUDA is available, print the GPU name and perform a test operation\n",
        "if cuda_available:\n",
        "    # Get the name of the GPU\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    print(f\"GPU Name: {gpu_name}\")\n",
        "\n",
        "    # Create a tensor and move it to the GPU\n",
        "    x = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n",
        "    print(f\"Tensor on GPU: {x}\")\n",
        "\n",
        "    # Perform a simple operation\n",
        "    y = x * 2\n",
        "    print(f\"Result of operation on GPU: {y}\")\n",
        "else:\n",
        "    print(\"CUDA is not available. Please check your PyTorch installation and GPU drivers.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efjmCOvW8B3d",
        "outputId": "3ef40a9a-4463-4665-8578-79209155bbfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7935a6682530>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "torch.autograd.set_detect_anomaly(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "adLpt7j7cuoL"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFn_iKM0dby8",
        "outputId": "c04402ae-7f1e-43fe-db99-c0b3d156d9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LwR5_uvTcuoL"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDccPM5AcuoL",
        "outputId": "aec4f2e6-d368-4fc4-eefe-c06bc979d076"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-29 18:13:48--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-12-29 18:13:48 (161 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Collab setup\n",
        "\n",
        "data_path = Path('data')\n",
        "data_path.mkdir(exist_ok=True)\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "!cp input.txt data/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0VBi6asbs4Vs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Datasets\n",
        "\n",
        "# Using tinyshakespeare\n",
        "\n",
        "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "####################################################################\n",
        "\n",
        "#Using BookCorpus\n",
        "\n",
        "# from datasets import load_dataset\n",
        "# data = load_dataset('bookcorpus/bookcorpus')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D1tbt7L2c-D",
        "outputId": "22cdce3d-d271-4277-985a-d5f09a3c1a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words:  202651\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Extracting the content of  the Dataset\n",
        "# Open a file for writing\n",
        "# with open('bookcorpus_text.txt', 'w', encoding='utf-8') as f:\n",
        "#     # Traverse the dataset and write text data to the file\n",
        "#     for record in data['train']['text']:\n",
        "#         f.write(record)\n",
        "\n",
        "# print(\"Writing to file complete.\")\n",
        "\n",
        "# Read the file contents into a single string\n",
        "with open('data/input.txt', 'r', encoding='utf-8') as f:\n",
        "    concatenated_text = f.read()\n",
        "\n",
        "# print(\"Reading from file and concatenation complete.\")\n",
        "# print(concatenated_text[:225000000])  # Print the first 1000 characters\n",
        "# print(f\"Total characters: {len(concatenated_text)}\")\n",
        "# print(\"Total words: \", len(concatenated_text.split()))\n",
        "\n",
        "#Using only 1% of the total characters (225 million out of 4.2 billion ->Total words:  45756831 )\n",
        "# concatenated_text = concatenated_text[:225000000]\n",
        "print(\"Total words: \", len(concatenated_text.split()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IG5ZV9KEcuoL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "#Subword level tokenization\n",
        "\n",
        "#Loading custom trained BPE\n",
        "# Load the tokenizer\n",
        "tokenizer = Tokenizer.from_file(\"bpe_tokenizer_tinyshakespeare_1k.json\")\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "# Encode and decode functions\n",
        "encode = lambda s: tokenizer.encode(s).ids\n",
        "decode = lambda l: tokenizer.decode(l)\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "#Character level tokenization\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "# chars = sorted(list(set(text)))\n",
        "# vocab_size = len(chars)\n",
        "\n",
        "\n",
        "# create a mapping from characters to integers\n",
        "# stoi = { ch: i for i,ch in enumerate(chars) }\n",
        "# itos = { i:ch for i,ch in enumerate(chars) }\n",
        "# encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "# decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ndPfBp-Gb0KN"
      },
      "outputs": [],
      "source": [
        "#Hyperparameters\n",
        "\n",
        "block_size = 256\n",
        "batch_size = 64\n",
        "embeddings_dims = 768\n",
        "attn_dropout = 0.1\n",
        "no_of_heads = 12 #IMP needs to be thoroughly calculated\n",
        "dropout = 0.1\n",
        "init_lambda = 0.8\n",
        "epochs = 100\n",
        "max_lr = 3e-4\n",
        "no_of_decoder_layers = 12 #IMP needs to be thoroughly calculated\n",
        "attn_dropout = 0.1\n",
        "weight_decay_optim = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "goaGJ8k1cuoM"
      },
      "outputs": [],
      "source": [
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHCaBcg_dby-",
        "outputId": "6119cef5-d658-4dbf-ad24-39c0039925fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "383747"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(data)\n",
        "# steps_per_epoch = 383747 / 64 = 6000\n",
        "#Tptal epochs = epcoh * steps_per_epoch = 1 * 6000 = 6000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qAhkF6nmcuoN"
      },
      "outputs": [],
      "source": [
        "# Text embeddings\n",
        "class TextEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size = vocab_size,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embeddings_table = nn.Embedding(num_embeddings = vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n",
        "        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.embeddings_table(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XllUd3tqcuoN"
      },
      "outputs": [],
      "source": [
        "#Position embeddings\n",
        "class PositionEmbeddings(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        block_size = block_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.position_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "        # nn.init.normal_(self.position_embeddings.weight.data, mean=0, std=0.02)\n",
        "\n",
        "    def forward(self):\n",
        "        return self.position_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "REUDHWrWcuoN"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Layer Normalization\n",
        "\n",
        "class RMSNormalization(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embeddings_dims = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer_norm = nn.RMSNorm(normalized_shape=embeddings_dims, eps=1e-5, elementwise_affine=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer_norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "x7rK9pejjzg1"
      },
      "outputs": [],
      "source": [
        "class Swish(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block_size: int = block_size,\n",
        "        embeddings_dims: int = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.sig = torch.nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        swish = x * self.sig(x)\n",
        "\n",
        "        return swish\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oc2tt-IAjz8T"
      },
      "outputs": [],
      "source": [
        "class SWiGLU(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        block_size: int = block_size,\n",
        "        embeddings_dims: int = embeddings_dims\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.swish = Swish(block_size=block_size, embeddings_dims=embeddings_dims)\n",
        "        self.linear_layer1 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False)\n",
        "        self.linear_layer2 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False)\n",
        "        self.linear_layer3 = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        swish_res = self.swish(self.linear_layer1(x))\n",
        "        x_V = self.linear_layer2(x)\n",
        "        res = torch.mul(swish_res, x_V)\n",
        "        out = self.linear_layer3(res)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lEe02cH9cuoN"
      },
      "outputs": [],
      "source": [
        "#FeedForward Neural Network\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dropout = dropout,\n",
        "        embeddings_size = embeddings_dims,\n",
        "        # inner_dimensional_states: int = 3072\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device)\n",
        "        self.swiglue = SWiGLU(block_size=block_size, embeddings_dims=embeddings_dims)\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.swiglue(x)\n",
        "        x = self.linear_layer(x)\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0Yv4qaTdcuoN"
      },
      "outputs": [],
      "source": [
        "# #Weights Initilization (for MLP Block)\n",
        "# def weights_init(m):\n",
        "#     classname = m.__class__.__name__\n",
        "#     if classname.find('Linear') != -1:\n",
        "#         nn.init.normal_(m.weight.data, 0.0, 0.02)  #mean = 0, std = 0.02\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cf0Jf_7UcuoN"
      },
      "outputs": [],
      "source": [
        "\n",
        "class AttentionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        lambda_init = init_lambda,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.head_size = embeddings_dims // no_of_heads\n",
        "        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n",
        "        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n",
        "        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.norm = RMSNormalization(embeddings_dims=self.head_size)\n",
        "        self.lambda_init = init_lambda\n",
        "\n",
        "        self.lambda_q1 = nn.Parameter(torch.zeros(self.head_size, device=device).normal_(mean=0,std=0.1))\n",
        "        self.lambda_q2 = nn.Parameter(torch.zeros(self.head_size, device=device).normal_(mean=0,std=0.1))\n",
        "        self.lambda_k1 = nn.Parameter(torch.zeros(self.head_size, device=device).normal_(mean=0,std=0.1))\n",
        "        self.lambda_k2 = nn.Parameter(torch.zeros(self.head_size, device=device).normal_(mean=0,std=0.1))\n",
        "        # self.lambda_final = torch.exp(self.lambda_q1 * self.lambda_k1) - torch.exp(self.lambda_q2 * self.lambda_k2) + lambda_init\n",
        "\n",
        "    def split(self, tensor: torch.tensor):\n",
        "\n",
        "        split_1 = tensor[:, :, :tensor.shape[-1] // 2 ]\n",
        "        split_2 = tensor[:, :, tensor.shape[-1] // 2:]\n",
        "        # print(\"split1: \", split_1.shape)\n",
        "        # print(\"split2: \", split_2.shape)\n",
        "        return (split_1, split_2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch, block_size, embd_dims = x.shape\n",
        "        k = self.keys(x)\n",
        "        q = self.query(x)\n",
        "        v = self.values(x)\n",
        "\n",
        "        k_1, k_2 = self.split(k)\n",
        "        q_1, q_2 = self.split(q)\n",
        "\n",
        "        self.lambda_final = torch.exp(torch.sum(self.lambda_q1 * self.lambda_k1, dim=-1)) - torch.exp(torch.sum(self.lambda_q2 * self.lambda_k2, dim=-1)) + self.lambda_init\n",
        "\n",
        "        # print(\"K2: \" , k_2.shape)\n",
        "        # print(\"q2: \", q_2.shape)\n",
        "        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n",
        "        weights_1 = q_1 @ torch.transpose(k_1, dim0=-2, dim1=-1) * (k_1.shape[-1] ** -0.5)\n",
        "        weights_2 = q_2 @ torch.transpose(k_2, dim0=-2, dim1=-1) * (k_2.shape[-1] ** -0.5)\n",
        "        # print(\"Weights 1: \", weights_1.shape)\n",
        "        # print(\"Weights 2: \", weights_2.shape)\n",
        "        masked_values_1 = weights_1.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
        "        masked_values_2 = weights_2.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n",
        "        weights_normalized_1 = nn.functional.softmax(masked_values_1, dim=-1) #Normalize along the embeddings dimension for all the tokens\n",
        "        weights_normalized_2 = nn.functional.softmax(masked_values_2, dim=-1)\n",
        "        # weights_normalized = self.dropout(weights_normalized)\n",
        "        # print(\"Weights: \", weights_normalized_1.shape)\n",
        "        # print(\"weights norm 1: \", (self.lambda_final * weights_normalized_2).shape)\n",
        "        # print(\"Lambda final: \", self.lambda_final)\n",
        "        out = (weights_normalized_1 - self.lambda_final * weights_normalized_2 )@ v\n",
        "        out = self.norm(out) * (1-init_lambda)\n",
        "        out = self.dropout(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "asiOs-sFcuoO"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MHA(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        lambda_init = init_lambda\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.norm = RMSNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.heads = nn.ModuleList([AttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n",
        "        self.dropout = nn.Dropout(p = attn_dropout)\n",
        "        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False)\n",
        "        # self.lambda_q1 = nn.Parameter(torch.randn(1, block_size, block_size, device=device))\n",
        "        # self.lambda_q2 = nn.Parameter(torch.randn(1, block_size, block_size, device=device))\n",
        "        # self.lambda_k1 = nn.Parameter(torch.randn(1, block_size, block_size, device=device))\n",
        "        # self.lambda_k2 = nn.Parameter(torch.randn(1, block_size, block_size, device=device))\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # self.lambda_final = (torch.exp(self.lambda_q1 * self.lambda_k1) - torch.exp(self.lambda_q2 * self.lambda_k2)) + lambda_init\n",
        "        concat = self.norm(torch.cat([head(x) for head in self.heads], dim=-1))\n",
        "        concat_norm = self.norm(concat)\n",
        "        linear_layer = self.linear(concat_norm)\n",
        "        out = self.dropout(linear_layer)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "s9rJzO_XcuoO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Decoder Block\n",
        "\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        dropout = dropout,\n",
        "        vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mha = MHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n",
        "        self.norm1 = RMSNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.norm2 = RMSNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"Hiii:\", x.shape)\n",
        "        x = x + self.norm1(self.mha(x))\n",
        "        # print(\"Hello: \", x.shape)\n",
        "        x = x + self.norm2(self.mlp_block(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "KGh8ujQJcuoO"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Decoder Block\n",
        "\n",
        "class DecoderModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        attn_dropout = attn_dropout,\n",
        "        embeddings_dims = embeddings_dims,\n",
        "        no_of_heads = no_of_heads,\n",
        "        block_size = block_size,\n",
        "        dropout = dropout,\n",
        "        no_of_decoder_layers = no_of_decoder_layers,\n",
        "        vocab_size = vocab_size\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.positional_embeddings = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True)\n",
        "        # self.positional_embeddings = PositionEmbeddings(block_size=block_size, embeddings_dims=embeddings_dims) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n",
        "        # torch.nn.init.normal_(self.positional_embeddings, mean=0.0, std=0.02)\n",
        "        self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n",
        "        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n",
        "        self.norm = RMSNormalization(embeddings_dims=embeddings_dims)\n",
        "        self.decoder_layers = nn.Sequential(*[TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout, vocab_size=vocab_size) for _ in range(no_of_decoder_layers)])\n",
        "        self.apply(self._init_weights)\n",
        "        self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    def _init_weights(self, module):  #Weight Initialization\n",
        "            if isinstance(module, nn.Linear):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.1)\n",
        "                if module.bias is not None:\n",
        "                    torch.nn.init.zeros_(module.bias)\n",
        "            elif isinstance(module, nn.Embedding):\n",
        "                torch.nn.init.normal_(module.weight, mean=0.0, std=0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.text_embds(x)\n",
        "        # print(\"AFTER: \", x.shape)\n",
        "        x = x + self.positional_embeddings\n",
        "        x = self.dropout(x)\n",
        "        # print(x.shape)\n",
        "        x = self.decoder_layers(x)\n",
        "        x = self.norm(x)\n",
        "        out = self.linear_layer(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tpmbUwBEcuoO"
      },
      "outputs": [],
      "source": [
        "#Instantiating the model\n",
        "model = DecoderModel(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, block_size=block_size, dropout=dropout, no_of_decoder_layers=no_of_decoder_layers, vocab_size=vocab_size)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOXtmG-lcuoO",
        "outputId": "7aca887f-77e5-4120-eb16-04f12b8984f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "DecoderModel (DecoderModel)                                  [64, 256]            [64, 256, 1000]      196,608              True\n",
              "├─TextEmbeddings (text_embds)                                [64, 256]            [64, 256, 768]       --                   True\n",
              "│    └─Embedding (embeddings_table)                          [64, 256]            [64, 256, 768]       768,000              True\n",
              "├─Dropout (dropout)                                          [64, 256, 768]       [64, 256, 768]       --                   --\n",
              "├─Sequential (decoder_layers)                                [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    └─TransformerDecoderBlock (0)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (1)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (2)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (3)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (4)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (5)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (6)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (7)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (8)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (9)                           [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (10)                          [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    └─TransformerDecoderBlock (11)                          [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    │    └─MHA (mha)                                        [64, 256, 768]       [64, 256, 768]       2,363,904            True\n",
              "│    │    └─RMSNormalization (norm1)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "│    │    └─MLPBlock (mlp_block)                             [64, 256, 768]       [64, 256, 768]       2,360,064            True\n",
              "│    │    └─RMSNormalization (norm2)                         [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "├─RMSNormalization (norm)                                    [64, 256, 768]       [64, 256, 768]       --                   True\n",
              "│    └─RMSNorm (layer_norm)                                  [64, 256, 768]       [64, 256, 768]       768                  True\n",
              "├─Linear (linear_layer)                                      [64, 256, 768]       [64, 256, 1000]      768,000              True\n",
              "============================================================================================================================================\n",
              "Total params: 58,439,424\n",
              "Trainable params: 58,439,424\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 3.73\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.13\n",
              "Forward/backward pass size (MB): 16035.87\n",
              "Params size (MB): 232.82\n",
              "Estimated Total Size (MB): 16268.83\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "\n",
        "#Printing a summary of the architecture\n",
        "from torchinfo import summary\n",
        "idx, targets = get_batch('test')\n",
        "# print(idx.shape)\n",
        "# idx = idx.to(device)\n",
        "summary(model=model,\n",
        "        input_data=idx,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "LH95cJEvcuoO"
      },
      "outputs": [],
      "source": [
        " # Optimizer setup and scheduler steup\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n",
        "total_steps = 2000\n",
        "eval_iters = 100\n",
        "# warmup_scheduler = warmup.LinearWarmup(optimizer, warmup_period=2000)\n",
        "# lr_scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=optimizer, T_max= total_steps - initial_iters)\n",
        "# lr_scheduler_linear = torch.optim.lr_scheduler.LinearLR(optimizer=optimizer, total_iters=initial_iters)\n",
        "\n",
        "@torch.inference_mode()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            idx, targets = get_batch(split=split)\n",
        "            logits = model(idx)\n",
        "            batch_size, block_size, embeddings_dims = logits.shape\n",
        "            logits = logits.view(batch_size*block_size, embeddings_dims) # Total tokens(words) => batch_size * block_size\n",
        "            targets = targets.view(batch_size * block_size)\n",
        "            loss = nn.functional.cross_entropy(logits, targets)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPrSPPu8cuoO",
        "outputId": "3086f547-632d-4423-fbae-4045a851c7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 100/2000 [08:39<2:43:41,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 100: train loss 8.3722, val loss 8.3632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 200/2000 [18:01<2:34:35,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 200: train loss 7.3941, val loss 7.4096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 300/2000 [27:24<2:25:55,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 300: train loss 6.8554, val loss 6.8805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 400/2000 [36:46<2:17:19,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 400: train loss 6.5609, val loss 6.5737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 500/2000 [46:09<2:09:28,  5.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 500: train loss 6.3883, val loss 6.4120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 600/2000 [55:35<2:00:42,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 600: train loss 6.2789, val loss 6.3017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 700/2000 [1:04:58<1:51:53,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 700: train loss 6.2082, val loss 6.2322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 800/2000 [1:14:20<1:43:58,  5.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 800: train loss 6.1570, val loss 6.1888\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 900/2000 [1:23:42<1:34:40,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 900: train loss 6.1198, val loss 6.1452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 1000/2000 [1:33:07<1:26:19,  5.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1000: train loss 6.0913, val loss 6.1139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 1100/2000 [1:42:30<1:17:27,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1100: train loss 6.0653, val loss 6.0859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 1200/2000 [1:51:51<1:08:52,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1200: train loss 6.0419, val loss 6.0662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 1300/2000 [2:01:14<1:01:27,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1300: train loss 6.0270, val loss 6.0487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 1400/2000 [2:10:38<52:08,  5.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1400: train loss 6.0127, val loss 6.0341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 1500/2000 [2:20:04<43:21,  5.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1500: train loss 6.0011, val loss 6.0283\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 1600/2000 [2:29:28<34:41,  5.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1600: train loss 5.9890, val loss 6.0091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 1700/2000 [2:38:51<25:56,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1700: train loss 5.9802, val loss 6.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1800/2000 [2:48:14<17:18,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1800: train loss 5.9713, val loss 5.9976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1900/2000 [2:57:36<08:38,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1900: train loss 5.9654, val loss 5.9913\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████▉| 1999/2000 [3:06:54<00:05,  5.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 1999: train loss 5.9556, val loss 5.9870\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2000/2000 [3:07:42<00:00,  5.63s/it]\n"
          ]
        }
      ],
      "source": [
        "#Train the  model\n",
        "from tqdm import tqdm\n",
        "\n",
        "model.train()\n",
        "for step in tqdm(range(total_steps)):\n",
        "\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if (step  % eval_iters == 0 and step != 0) or step == total_steps - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "        # torch.save(model.state_dict(), 'weights/_differential_transformer_86M_steps_%d.pth' % (step))\n",
        "\n",
        "    idx, targets = get_batch(split='train')\n",
        "    logits = model(idx)\n",
        "    batch_size, block_size, embeddings_dims = logits.shape\n",
        "    logits = logits.view(batch_size*block_size, embeddings_dims)\n",
        "    targets = targets.view(batch_size * block_size)\n",
        "    loss = nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(loss.item())\n",
        "    # break\n",
        "\n",
        "    # if step != 0 and (step % eval_iters == 0 or step == total_steps -1) :\n",
        "    #     loss_values = estimate_loss()\n",
        "    #     print(\"Train Loss at {} steps : {}\".format(step, loss.item()), \"Val Loss at {} steps : {}\".format(step, loss_values['val']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ldAZ_nwNi5WQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}