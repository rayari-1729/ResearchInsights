{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install -q torch==2.2.0 torchtext==0.17.0\n!python -m spacy download de","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZ8MZf2sjKI7","outputId":"479153b2-3869-495e-f90b-6cb8b3aac3cf","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:14.849859Z","iopub.execute_input":"2024-12-30T23:41:14.850460Z","iopub.status.idle":"2024-12-30T23:41:25.813585Z","shell.execute_reply.started":"2024-12-30T23:41:14.850416Z","shell.execute_reply":"2024-12-30T23:41:25.812564Z"}},"outputs":[{"name":"stdout","text":"\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\nfull pipeline package name 'de_core_news_sm' instead.\u001b[0m\nCollecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.6)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.9.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (71.0.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.23.4)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.8.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom pathlib import Path\nfrom tokenizers import Tokenizer\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"id":"Pw7f2ghccuoK","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:25.815482Z","iopub.execute_input":"2024-12-30T23:41:25.815754Z","iopub.status.idle":"2024-12-30T23:41:27.153981Z","shell.execute_reply.started":"2024-12-30T23:41:25.815732Z","shell.execute_reply":"2024-12-30T23:41:27.153285Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\ntorch.__version__","metadata":{"id":"aW5k-CsTj7ZP","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"e9449ec6-3e98-4c09-acb4-cf0cf887e703","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:27.155145Z","iopub.execute_input":"2024-12-30T23:41:27.155526Z","iopub.status.idle":"2024-12-30T23:41:27.161220Z","shell.execute_reply.started":"2024-12-30T23:41:27.155490Z","shell.execute_reply":"2024-12-30T23:41:27.160393Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.2.0+cu121'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# device = \"cpu\"\ndevice","metadata":{"id":"adLpt7j7cuoL","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"5d35ff16-bf18-4940-eed3-054cba8f547b","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:27.162059Z","iopub.execute_input":"2024-12-30T23:41:27.162394Z","iopub.status.idle":"2024-12-30T23:41:27.218628Z","shell.execute_reply.started":"2024-12-30T23:41:27.162363Z","shell.execute_reply":"2024-12-30T23:41:27.217578Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\ncuda_available = torch.cuda.is_available()\nprint(f\"CUDA available: {cuda_available}\")\n\n# If CUDA is available, print the GPU name and perform a test operation\nif cuda_available:\n    # Get the name of the GPU\n    gpu_name = torch.cuda.get_device_name(0)\n    print(f\"GPU Name: {gpu_name}\")\n\n    # Create a tensor and move it to the GPU\n    x = torch.tensor([1.0, 2.0, 3.0], device='cuda')\n    print(f\"Tensor on GPU: {x}\")\n\n    # Perform a simple operation\n    y = x * 2\n    print(f\"Result of operation on GPU: {y}\")\nelse:\n    print(\"CUDA is not available. Please check your PyTorch installation and GPU drivers.\")","metadata":{"id":"Yk3urEOwjHyM","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:27.219603Z","iopub.execute_input":"2024-12-30T23:41:27.219915Z","iopub.status.idle":"2024-12-30T23:41:27.512559Z","shell.execute_reply.started":"2024-12-30T23:41:27.219890Z","shell.execute_reply":"2024-12-30T23:41:27.511665Z"}},"outputs":[{"name":"stdout","text":"CUDA available: True\nGPU Name: Tesla T4\nTensor on GPU: tensor([1., 2., 3.], device='cuda:0')\nResult of operation on GPU: tensor([2., 4., 6.], device='cuda:0')\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#Data","metadata":{"id":"LwR5_uvTcuoL","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:27.513428Z","iopub.execute_input":"2024-12-30T23:41:27.513712Z","iopub.status.idle":"2024-12-30T23:41:27.517228Z","shell.execute_reply.started":"2024-12-30T23:41:27.513688Z","shell.execute_reply":"2024-12-30T23:41:27.516268Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import torchtext\nimport torch\nfrom torchtext.data.utils import get_tokenizer\nfrom collections import Counter\nfrom torchtext.vocab import Vocab\nfrom torchtext.utils import download_from_url, extract_archive\nimport io\n\nurl_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\ntrain_urls = ('train.de.gz', 'train.en.gz')\nval_urls = ('val.de.gz', 'val.en.gz')\ntest_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n\ntrain_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\nval_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\ntest_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n\nde_tokenizer = get_tokenizer('spacy', language='de')\nen_tokenizer = get_tokenizer('spacy', language='en')\n\nfrom torchtext.vocab import build_vocab_from_iterator\n\ndef build_vocab(filepath, tokenizer):\n    counter = Counter()\n    with io.open(filepath, encoding=\"utf8\") as f:\n        for string_ in f:\n            counter.update(tokenizer(string_))\n    # Ensure '<pad>' is at index 0 by placing it first in the specials list\n    vocab = build_vocab_from_iterator(\n        [counter.keys()],\n        specials=['<pad>', '<unk>', '<bos>', '<eos>']  # '<pad>' comes first\n    )\n    vocab.set_default_index(vocab['<unk>'])\n    return vocab\n\n\nde_vocab = build_vocab(train_filepaths[0], de_tokenizer)\nen_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n\ndef data_process(filepaths):\n  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n  data = []\n  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n                            dtype=torch.long)\n    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n                            dtype=torch.long)\n    data.append((de_tensor_, en_tensor_))\n  return data\n\ntrain_data = data_process(train_filepaths)\nval_data = data_process(val_filepaths)\ntest_data = data_process(test_filepaths)","metadata":{"id":"uEN3FPxEjHyP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7ac615fa-3a78-4936-ff9d-62771019ee80","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:27.518288Z","iopub.execute_input":"2024-12-30T23:41:27.518612Z","iopub.status.idle":"2024-12-30T23:41:37.946170Z","shell.execute_reply.started":"2024-12-30T23:41:27.518583Z","shell.execute_reply":"2024-12-30T23:41:37.945437Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(f\"DE <pad> index: {de_vocab['<pad>']}\")\nprint(f\"EN <pad> index: {en_vocab['<pad>']}\")\n","metadata":{"id":"uJ5yZMaQMxb1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dbc051d0-2442-46d5-89d7-dae61c9a4c79","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:37.948746Z","iopub.execute_input":"2024-12-30T23:41:37.949239Z","iopub.status.idle":"2024-12-30T23:41:37.954281Z","shell.execute_reply.started":"2024-12-30T23:41:37.949170Z","shell.execute_reply":"2024-12-30T23:41:37.953375Z"}},"outputs":[{"name":"stdout","text":"DE <pad> index: 0\nEN <pad> index: 0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#Hyperparameters\n\nblock_size = 256\nbatch_size = 64\nsrc_vocab_size = len(de_vocab)\ntgt_vocab_size = len(en_vocab)\nembeddings_dims = 384\nattn_dropout = 0.1\nno_of_heads = 6 #IMP needs to be thoroughly calculated\ndropout = 0.1\nepochs = 3\nmax_lr = 2e-4\nno_of_decoder_layers = 6 #IMP needs to be thoroughly calculated\nattn_dropout = 0.1\nweight_decay_optim = 0.01","metadata":{"id":"D7AP219KJzTs","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:37.955961Z","iopub.execute_input":"2024-12-30T23:41:37.956230Z","iopub.status.idle":"2024-12-30T23:41:37.968761Z","shell.execute_reply.started":"2024-12-30T23:41:37.956179Z","shell.execute_reply":"2024-12-30T23:41:37.967954Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# from textwrap import indent\n# # Custom collate function for padding\n# from torch.nn.utils.rnn import pad_sequence\n\n# def collate_fn(batch):\n#     # Separate inputs and targets\n#     inputs, targets = zip(*batch)\n\n#     # Pad input sequences\n#     inputs_padded = pad_sequence([torch.tensor(seq) for seq in inputs], batch_first=True, padding_value=0)\n\n#     # Pad target sequences (if targets are sequences) or convert them to a tensor\n#     targets_padded = pad_sequence([torch.tensor(seq) for seq in targets], batch_first=True, padding_value=0)\n\n#     return inputs_padded, targets_padded\n\nimport torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nBATCH_SIZE = batch_size\nPAD_IDX = de_vocab['<pad>']\nBOS_IDX = de_vocab['<bos>']\nEOS_IDX = de_vocab['<eos>']\n\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\n\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\n\n# Constants\nMAX_LENGTH = block_size  # Desired sequence length for padding\n\ndef generate_batch(data_batch):\n    de_batch, en_batch, src_padding_masks, tgt_padding_masks= [], [], [], []\n    for (de_item, en_item) in data_batch:\n        # Ensure <BOS> is at the beginning and <EOS> at the end\n        de_item = torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0)\n        en_item = torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0)\n\n        # Manually pad sequences to the maximum length (256 in this case)\n        de_item_padded = F.pad(de_item, (0, MAX_LENGTH - de_item.size(0)), value=PAD_IDX)\n        en_item_padded = F.pad(en_item, (0, MAX_LENGTH - en_item.size(0)), value=PAD_IDX)\n\n         # Generate padding masks (1 for non-padding, 0 for padding)\n        src_mask = (de_item_padded != PAD_IDX).int()  # Source mask\n        tgt_mask = (en_item_padded != PAD_IDX).int()  # Target mask\n\n        # Append to the batch\n        de_batch.append(de_item_padded)\n        en_batch.append(en_item_padded)\n        src_padding_masks.append(src_mask)\n        tgt_padding_masks.append(tgt_mask)\n\n    # Stack batches together\n    de_batch = torch.stack(de_batch, dim=0)\n    en_batch = torch.stack(en_batch, dim=0)\n    src_padding_masks = torch.stack(src_padding_masks, dim=0)  # Shape: (batch_size, MAX_LENGTH)\n    tgt_padding_masks = torch.stack(tgt_padding_masks, dim=0)  # Shape: (batch_size, MAX_LENGTH)\n\n    return de_batch, en_batch, src_padding_masks, tgt_padding_masks\n\n# DataLoader with the custom collate_fn\ntrain_dataloader = DataLoader(train_data, batch_size=batch_size,\n                               shuffle=True, collate_fn=generate_batch)\nval_dataloader = DataLoader(val_data, batch_size=batch_size,\n                             shuffle=False, collate_fn=generate_batch)\n# test_iter = DataLoader(test_data, batch_size=batch_size,\n#                        shuffle=True, collate_fn=generate_batch)\n\n\n","metadata":{"id":"LQ6lYiGJLTDq","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:37.969525Z","iopub.execute_input":"2024-12-30T23:41:37.969812Z","iopub.status.idle":"2024-12-30T23:41:37.985084Z","shell.execute_reply.started":"2024-12-30T23:41:37.969779Z","shell.execute_reply":"2024-12-30T23:41:37.984149Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"\n\n# #Dataloaders\n# train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n# val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n# test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)","metadata":{"id":"jXuim2eLI4gu","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:37.985968Z","iopub.execute_input":"2024-12-30T23:41:37.986292Z","iopub.status.idle":"2024-12-30T23:41:38.000621Z","shell.execute_reply.started":"2024-12-30T23:41:37.986261Z","shell.execute_reply":"2024-12-30T23:41:37.999881Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Get the vocabulary size for German and English\ngerman_vocab_size = len(de_vocab)\nenglish_vocab_size = len(en_vocab)\n\nprint(f\"German Vocabulary Size: {german_vocab_size}\")\nprint(f\"English Vocabulary Size: {english_vocab_size}\")","metadata":{"id":"Qi_iCJxbpbAS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05705705-7c1d-4524-abbc-198a8ccb8dc8","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.001642Z","iopub.execute_input":"2024-12-30T23:41:38.001933Z","iopub.status.idle":"2024-12-30T23:41:38.013974Z","shell.execute_reply.started":"2024-12-30T23:41:38.001903Z","shell.execute_reply":"2024-12-30T23:41:38.013055Z"}},"outputs":[{"name":"stdout","text":"German Vocabulary Size: 19215\nEnglish Vocabulary Size: 10838\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"next(iter(train_dataloader))","metadata":{"id":"jkzEorgmo-JS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca90003b-f309-4d3e-edcb-ad7a5a02a5fa","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.014968Z","iopub.execute_input":"2024-12-30T23:41:38.015271Z","iopub.status.idle":"2024-12-30T23:41:38.038436Z","shell.execute_reply.started":"2024-12-30T23:41:38.015246Z","shell.execute_reply":"2024-12-30T23:41:38.037608Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(tensor([[    2,  2473, 15830,  ...,     0,     0,     0],\n         [    2,  2481,  6546,  ...,     0,     0,     0],\n         [    2,  2481,  4170,  ...,     0,     0,     0],\n         ...,\n         [    2,  2473, 13509,  ...,     0,     0,     0],\n         [    2,  2473,  6546,  ...,     0,     0,     0],\n         [    2,  2473,  6546,  ...,     0,     0,     0]]),\n tensor([[    2,   102, 10819,  ...,     0,     0,     0],\n         [    2,   102,  6509,  ...,     0,     0,     0],\n         [    2,   102,  5371,  ...,     0,     0,     0],\n         ...,\n         [    2,   102,  6365,  ...,     0,     0,     0],\n         [    2,   102,  6509,  ...,     0,     0,     0],\n         [    2,   102,  6509,  ...,     0,     0,     0]]),\n tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32),\n tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32))"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"\n# for x, y in train_dataloader:\n#     print(x.shape)\n#     print(y.shape)\n#     break","metadata":{"id":"jhhR2b3dOjJY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e55b08b6-4a23-4d96-cf20-aeda8cc17655","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.039313Z","iopub.execute_input":"2024-12-30T23:41:38.039608Z","iopub.status.idle":"2024-12-30T23:41:38.042776Z","shell.execute_reply.started":"2024-12-30T23:41:38.039577Z","shell.execute_reply":"2024-12-30T23:41:38.041938Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Text embeddings\nclass TgtTextEmbeddings(nn.Module):\n    def __init__(\n        self,\n        vocab_size = tgt_vocab_size,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.embeddings_table = nn.Embedding(num_embeddings = tgt_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n\n    def forward(self, x):\n        return self.embeddings_table(x)","metadata":{"id":"R9CSiuD2jHyT","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.043739Z","iopub.execute_input":"2024-12-30T23:41:38.044041Z","iopub.status.idle":"2024-12-30T23:41:38.053157Z","shell.execute_reply.started":"2024-12-30T23:41:38.044011Z","shell.execute_reply":"2024-12-30T23:41:38.052522Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Text embeddings\nclass SrcTextEmbeddings(nn.Module):\n    def __init__(\n        self,\n        vocab_size = src_vocab_size,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.embeddings_table = nn.Embedding(num_embeddings = src_vocab_size, embedding_dim=embeddings_dims, device=device) #Just a look up table to convert the toekns_ids to some numbers\n        # nn.init.normal_(self.embeddings_table.weight.data, mean=0, std=0.02)\n\n    def forward(self, x):\n        return self.embeddings_table(x)","metadata":{"id":"qAhkF6nmcuoN","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.053981Z","iopub.execute_input":"2024-12-30T23:41:38.054262Z","iopub.status.idle":"2024-12-30T23:41:38.068207Z","shell.execute_reply.started":"2024-12-30T23:41:38.054239Z","shell.execute_reply":"2024-12-30T23:41:38.067509Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\n#Layer Normalization\n\nclass LayerNormalization(nn.Module):\n    def __init__(\n        self,\n        embeddings_dims = embeddings_dims\n    ):\n        super().__init__()\n        self.norm = nn.LayerNorm(normalized_shape=embeddings_dims)\n    def forward(self, x):\n\n        return self.norm(x)","metadata":{"id":"REUDHWrWcuoN","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.068924Z","iopub.execute_input":"2024-12-30T23:41:38.069221Z","iopub.status.idle":"2024-12-30T23:41:38.079344Z","shell.execute_reply.started":"2024-12-30T23:41:38.069166Z","shell.execute_reply":"2024-12-30T23:41:38.078634Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\n#FeedForward Neural Network\n\nclass MLPBlock(nn.Module):\n    def __init__(\n        self,\n        dropout = dropout,\n        embeddings_size = embeddings_dims,\n        # inner_dimensional_states: int = 3072\n    ):\n        super().__init__()\n\n        self.mlp = nn.Sequential(\n            nn.Linear(device=device, in_features=embeddings_size, out_features= 4 * embeddings_dims),\n            nn.GELU(),\n            nn.Linear(device=device, in_features= 4 * embeddings_dims, out_features=embeddings_size),\n            nn.Dropout(p = dropout)\n        )\n\n    def forward(self, x):\n        # mlp_weights_init = self.mlp.apply(weights_init)\n        return self.mlp(x)","metadata":{"id":"lEe02cH9cuoN","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.080282Z","iopub.execute_input":"2024-12-30T23:41:38.080590Z","iopub.status.idle":"2024-12-30T23:41:38.093224Z","shell.execute_reply.started":"2024-12-30T23:41:38.080556Z","shell.execute_reply":"2024-12-30T23:41:38.092377Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\nclass MaskedAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, x):\n        batch, block_size, embd_dims = x.shape\n        k = self.keys(x)\n        q = self.query(x)\n        v = self.values(x)\n        masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        masked_values = weights.masked_fill(masked_table[: block_size, : block_size] == 0, float('-inf'))\n        weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n        weights_normalized = self.dropout(weights_normalized)\n        out = weights_normalized @ v\n        return out\n","metadata":{"id":"cf0Jf_7UcuoN","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.094129Z","iopub.execute_input":"2024-12-30T23:41:38.094455Z","iopub.status.idle":"2024-12-30T23:41:38.107217Z","shell.execute_reply.started":"2024-12-30T23:41:38.094424Z","shell.execute_reply":"2024-12-30T23:41:38.106611Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nclass MaskedMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([MaskedAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, x):\n        concat = torch.cat([head(x) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"id":"OUFERSL2u8LT","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.108072Z","iopub.execute_input":"2024-12-30T23:41:38.108386Z","iopub.status.idle":"2024-12-30T23:41:38.122997Z","shell.execute_reply.started":"2024-12-30T23:41:38.108365Z","shell.execute_reply":"2024-12-30T23:41:38.122019Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#Single Attention Head\n\nclass CrossAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, query, key, value, mask=None):\n        # batch, block_size, embd_dims = x.shape\n\n        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = query @ torch.transpose(key, dim0=-2, dim1=-1) * (key.shape[-1] ** -0.5)\n        if(mask != None):\n            mask = mask.unsqueeze(1)\n            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ value\n            out = self.dropout(out)\n            return out\n        else:\n            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ value\n            out = self.dropout(out)\n            return out","metadata":{"id":"oGGyyF4pjHyd","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.123871Z","iopub.execute_input":"2024-12-30T23:41:38.124170Z","iopub.status.idle":"2024-12-30T23:41:38.136893Z","shell.execute_reply.started":"2024-12-30T23:41:38.124133Z","shell.execute_reply":"2024-12-30T23:41:38.136282Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#Single Attention Head\n\nclass FullAttentionHead(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.head_size = embeddings_dims // no_of_heads\n        self.query = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device, bias=False)\n        self.keys = nn.Linear(in_features=embeddings_dims, out_features=self.head_size,device=device, bias=False)\n        self.values = nn.Linear(in_features=embeddings_dims, out_features=self.head_size, device=device,bias=False)\n        self.dropout = nn.Dropout(p = attn_dropout)\n\n\n    def forward(self, x, mask=None):\n        # batch, block_size, embd_dims = x.shape\n        k = self.keys(x)\n        q = self.query(x)\n        v = self.values(x)\n        # masked_table = torch.tril(torch.ones(block_size, block_size, device=device))\n        weights = q @ torch.transpose(k, dim0=-2, dim1=-1) * (k.shape[-1] ** -0.5)\n        if(mask != None):\n            mask = mask.unsqueeze(1)\n            masked_values = weights.masked_fill(mask == 0, float('-inf'))\n            weights_normalized = nn.functional.softmax(masked_values, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ v\n            out = self.dropout(out)\n            return out\n        else:\n            weights_normalized = nn.functional.softmax(weights, dim=-1) #Normalize along the embeddings dimension for all the tokens\n            # weights_normalized = self.dropout(weights_normalized)\n            out = weights_normalized @ v\n            out = self.dropout(out)\n            return out","metadata":{"id":"U5NmszzcjHyf","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.137820Z","iopub.execute_input":"2024-12-30T23:41:38.138084Z","iopub.status.idle":"2024-12-30T23:41:38.151910Z","shell.execute_reply.started":"2024-12-30T23:41:38.138064Z","shell.execute_reply":"2024-12-30T23:41:38.150743Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\nclass FullMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([FullAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, x, mask=None):\n        concat = torch.cat([head(x, mask) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"id":"v_BB7r7kqmOc","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.152929Z","iopub.execute_input":"2024-12-30T23:41:38.153253Z","iopub.status.idle":"2024-12-30T23:41:38.167755Z","shell.execute_reply.started":"2024-12-30T23:41:38.153220Z","shell.execute_reply":"2024-12-30T23:41:38.166944Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"\n\nclass CrossMHA(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n    ):\n        super().__init__()\n        self.heads = nn.ModuleList([CrossAttentionHead(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads) for _ in range(no_of_heads)])\n        self.dropout = nn.Dropout(p = attn_dropout)\n        self.linear = nn.Linear(in_features=no_of_decoder_layers * embeddings_dims, out_features=embeddings_dims, device=device, bias=False) # 12 (no of heads) * (batch_size) 64 = 768 -> gives out the text embeddings\n\n    def forward(self, query, key, x, mask=None):\n        concat = torch.cat([head(query, key, x,  mask) for head in self.heads], dim=-1)\n        linear_layer = self.linear(concat)\n        out = self.dropout(linear_layer)\n        return out","metadata":{"id":"TTwRkBzcvE-_","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.168778Z","iopub.execute_input":"2024-12-30T23:41:38.169064Z","iopub.status.idle":"2024-12-30T23:41:38.193706Z","shell.execute_reply.started":"2024-12-30T23:41:38.169035Z","shell.execute_reply":"2024-12-30T23:41:38.192606Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Decoder Block\n\nclass TransformerDecoderBlock(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        dropout = dropout,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n        self.cross = CrossMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.masked = MaskedMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.layer_norm1 = LayerNormalization(embeddings_dims)\n        self.layer_norm2 = LayerNormalization(embeddings_dims)\n        # self.layer_norm3 = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.layer_norm4 = LayerNormalization(embeddings_dims)\n        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n\n    def forward(self, query, key, x, mask=None):\n        x = self.layer_norm1(x + self.masked(x)) #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n        x = self.layer_norm2(x + self.cross(query, key, x, mask)) #Very important step\n        # x = x + self.mha(self.layer_norm1(x))  #Very important step -> Layer Norm on input and then passes it to the subsequent blocks\n        x = self.layer_norm4(x + self.mlp_block(x)) #Very important step\n\n        return x","metadata":{"id":"s9rJzO_XcuoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.194673Z","iopub.execute_input":"2024-12-30T23:41:38.194950Z","iopub.status.idle":"2024-12-30T23:41:38.201695Z","shell.execute_reply.started":"2024-12-30T23:41:38.194926Z","shell.execute_reply":"2024-12-30T23:41:38.200801Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Decoder Block\n\nclass DecoderModel(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        block_size = block_size,\n        dropout = dropout,\n        no_of_decoder_layers = no_of_decoder_layers,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n\n        # self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n\n\n        # torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n\n        # self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n\n\n        self.tgt_text_embds = TgtTextEmbeddings(vocab_size=tgt_vocab_size, embeddings_dims=embeddings_dims)\n        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n        # self.layer_norm = LayerNormalization(embeddings_dims=embeddings_dims)\n        self.decoder_layers = nn.ModuleList([TransformerDecoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n        self.apply(self._init_weights)\n        self.positional_embeddings_tgt = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n        torch.nn.init.normal_(self.positional_embeddings_tgt, mean=0.0, std=0.02)\n\n        # out = self.decoder_layers(query, key, x)\n        # Loop through each decoder layer\n    def _init_weights(self, module):  #Weight Initialization\n            if isinstance(module, nn.Linear):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    torch.nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, query, key, x, mask):\n        x = self.tgt_text_embds(x)\n        x = x + self.positional_embeddings_tgt\n        for decoder_layer in self.decoder_layers:\n            x = decoder_layer(query, key, x, mask)\n        # x = self.layer_norm(x)\n\n        return x","metadata":{"id":"KGh8ujQJcuoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.206020Z","iopub.execute_input":"2024-12-30T23:41:38.206345Z","iopub.status.idle":"2024-12-30T23:41:38.223220Z","shell.execute_reply.started":"2024-12-30T23:41:38.206310Z","shell.execute_reply":"2024-12-30T23:41:38.222390Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"","metadata":{"id":"tpmbUwBEcuoO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#Encoder","metadata":{"id":"A3SgKrC-jHyd","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.224514Z","iopub.execute_input":"2024-12-30T23:41:38.224795Z","iopub.status.idle":"2024-12-30T23:41:38.237595Z","shell.execute_reply.started":"2024-12-30T23:41:38.224767Z","shell.execute_reply":"2024-12-30T23:41:38.236768Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"\n\n\nclass TransformerEncoderBlock(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        dropout = dropout,\n        mask=None\n    ):\n        super().__init__()\n\n        self.mha = FullMHA(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads)\n        self.layer_norm1 = LayerNormalization(embeddings_dims)\n        self.layer_norm2 = LayerNormalization(embeddings_dims)\n        self.mlp_block = MLPBlock(dropout=dropout, embeddings_size=embeddings_dims)\n\n    def forward(self, x, mask=None):\n        x = self.layer_norm1(x + self.mha(x, mask))\n        x = self.layer_norm2(x + self.mlp_block(x))\n\n        return x","metadata":{"id":"v6mbbO3yp-gh","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.238404Z","iopub.execute_input":"2024-12-30T23:41:38.238697Z","iopub.status.idle":"2024-12-30T23:41:38.247055Z","shell.execute_reply.started":"2024-12-30T23:41:38.238669Z","shell.execute_reply":"2024-12-30T23:41:38.246135Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"\n\nclass EncoderModel(nn.Module):\n    def __init__(\n        self,\n        attn_dropout = attn_dropout,\n        embeddings_dims = embeddings_dims,\n        no_of_heads = no_of_heads,\n        block_size = block_size,\n        dropout = dropout,\n        no_of_decoder_layers = no_of_decoder_layers,\n        # vocab_size = vocab_size\n    ):\n        super().__init__()\n\n        # self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n\n        # torch.nn.init.normal_(self.positional_embeddings_src, mean=0.0, std=0.02)\n\n        # self.text_embds = TextEmbeddings(vocab_size=vocab_size, embeddings_dims=embeddings_dims)\n\n        self.positional_embeddings_src = nn.Parameter(torch.randn(1, block_size, embeddings_dims, device=device), requires_grad=True) #To give positional embeddings to each token of the input text, hence num_embeddings=block_size\n        torch.nn.init.normal_(self.positional_embeddings_src, mean=0.0, std=0.02)\n\n        self.src_text_embeds = SrcTextEmbeddings(vocab_size=src_vocab_size, embeddings_dims=embeddings_dims)\n\n        self.encoder_layers = nn.ModuleList([TransformerEncoderBlock(attn_dropout=attn_dropout, embeddings_dims=embeddings_dims, no_of_heads=no_of_heads, dropout=dropout) for _ in range(no_of_decoder_layers)])\n        self.apply(self._init_weights)\n\n    def _init_weights(self, module):  #Weight Initialization\n            if isinstance(module, nn.Linear):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n                if module.bias is not None:\n                    torch.nn.init.zeros_(module.bias)\n            elif isinstance(module, nn.Embedding):\n                torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n\n    def forward(self, x, mask):\n\n        # print(x.shape)\n        x = self.src_text_embeds(x)\n        # print(self.positional_embeddings_src.shape)\n        # print(x.shape)\n        x = x + self.positional_embeddings_src\n\n        # print(x.shape)\n        # Loop through each encoder layer\n        for encoder_layer in self.encoder_layers:\n            x = encoder_layer(x, mask)\n        return x\n\n","metadata":{"id":"HxW0pvnV12Ms","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.247952Z","iopub.execute_input":"2024-12-30T23:41:38.248257Z","iopub.status.idle":"2024-12-30T23:41:38.262347Z","shell.execute_reply.started":"2024-12-30T23:41:38.248229Z","shell.execute_reply":"2024-12-30T23:41:38.261499Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\nclass Transformer(nn.Module):\n    def __init__(\n        self,\n\n    ):\n        super().__init__()\n\n        self.encoder = EncoderModel()\n        self.decoder = DecoderModel()\n        self.linear_layer = nn.Linear(in_features=embeddings_dims, out_features=tgt_vocab_size, device=device, bias=False) # Takes in logits of dimensions- embeds_dims and converts it into dimension of vocab_size (logits in range of vocab_size)\n\n\n    def forward(self, src, tgt, src_mask, tgt_mask):\n        x = self.encoder(src, src_mask)\n        x = self.decoder(x, x, tgt, None)\n        out = self.linear_layer(x)\n        return out\n\n","metadata":{"id":"2UWijIFl2Ykd","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.263313Z","iopub.execute_input":"2024-12-30T23:41:38.263631Z","iopub.status.idle":"2024-12-30T23:41:38.278543Z","shell.execute_reply.started":"2024-12-30T23:41:38.263563Z","shell.execute_reply":"2024-12-30T23:41:38.277881Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#Instantiating the model\nmodel = Transformer()\nmodel = model.to(device)\n","metadata":{"id":"ntIaQj1U3pFX","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.279081Z","iopub.execute_input":"2024-12-30T23:41:38.279371Z","iopub.status.idle":"2024-12-30T23:41:38.562125Z","shell.execute_reply.started":"2024-12-30T23:41:38.279345Z","shell.execute_reply":"2024-12-30T23:41:38.561113Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_data[2][1][1].shape","metadata":{"id":"FVsCsep95J9a","colab":{"base_uri":"https://localhost:8080/"},"outputId":"de4f6be8-e987-4cce-a10f-317f42f837b3","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.563144Z","iopub.execute_input":"2024-12-30T23:41:38.563536Z","iopub.status.idle":"2024-12-30T23:41:38.570127Z","shell.execute_reply.started":"2024-12-30T23:41:38.563503Z","shell.execute_reply":"2024-12-30T23:41:38.569260Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([])"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"\n#Printing a summary of the architecture\n!pip install torchinfo\nfrom torchinfo import summary\n# idx, targets = get_batch('test')\n# idx = idx.to(device)\n\n# Generate random sample data\nsrc_data = torch.randint(1, src_vocab_size, (batch_size, block_size)).to(device)  # (batch_size, seq_length)\ntgt_data = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  # (batch_size, seq_length)\nsrc_mask = torch.randint(1, src_vocab_size, (batch_size, block_size)).to(device)  # \ntgt_mask = torch.randint(1, tgt_vocab_size, (batch_size, block_size)).to(device)  #\n# print(src_data.shape)\nsummary(model=model,\n        input_data=(src_data, tgt_data, src_mask, tgt_mask),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"])","metadata":{"id":"yOXtmG-lcuoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:38.571114Z","iopub.execute_input":"2024-12-30T23:41:38.571435Z","iopub.status.idle":"2024-12-30T23:41:42.449903Z","shell.execute_reply.started":"2024-12-30T23:41:38.571405Z","shell.execute_reply":"2024-12-30T23:41:42.448944Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"=======================================================================================================================================\nLayer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n=======================================================================================================================================\nTransformer (Transformer)                               [64, 256]            [64, 256, 10838]     --                   True\n├─EncoderModel (encoder)                                [64, 256]            [64, 256, 384]       98,304               True\n│    └─SrcTextEmbeddings (src_text_embeds)              [64, 256]            [64, 256, 384]       --                   True\n│    │    └─Embedding (embeddings_table)                [64, 256]            [64, 256, 384]       7,378,560            True\n│    └─ModuleList (encoder_layers)                      --                   --                   --                   True\n│    │    └─TransformerEncoderBlock (0)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n│    │    └─TransformerEncoderBlock (1)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n│    │    └─TransformerEncoderBlock (2)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n│    │    └─TransformerEncoderBlock (3)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n│    │    └─TransformerEncoderBlock (4)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n│    │    └─TransformerEncoderBlock (5)                 [64, 256, 384]       [64, 256, 384]       1,772,928            True\n├─DecoderModel (decoder)                                [64, 256, 384]       [64, 256, 384]       4,260,096            True\n│    └─TgtTextEmbeddings (tgt_text_embds)               [64, 256]            [64, 256, 384]       --                   True\n│    │    └─Embedding (embeddings_table)                [64, 256]            [64, 256, 384]       4,161,792            True\n│    └─ModuleList (decoder_layers)                      --                   --                   --                   True\n│    │    └─TransformerDecoderBlock (0)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n│    │    └─TransformerDecoderBlock (1)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n│    │    └─TransformerDecoderBlock (2)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n│    │    └─TransformerDecoderBlock (3)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n│    │    └─TransformerDecoderBlock (4)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n│    │    └─TransformerDecoderBlock (5)                 [64, 256, 384]       [64, 256, 384]       3,100,800            True\n├─Linear (linear_layer)                                 [64, 256, 384]       [64, 256, 10838]     4,161,792            True\n=======================================================================================================================================\nTotal params: 49,302,912\nTrainable params: 49,302,912\nNon-trainable params: 0\nTotal mult-adds (G): 2.71\n=======================================================================================================================================\nInput size (MB): 0.52\nForward/backward pass size (MB): 8768.98\nParams size (MB): 169.16\nEstimated Total Size (MB): 8938.66\n======================================================================================================================================="},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"# Optimizer setup and scheduler steup\nout = {\"Train\": None, \"val\": None}\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr)\n# optimizer = torch.optim.Adam(model.parameters(), lr=max_lr, weight_decay=weight_decay_optim)\n# initial_iters = 2000\n# total_steps = 10000\neval_iters = 5\nloss_fn = nn.CrossEntropyLoss()\ncount = 0\n\n@torch.inference_mode()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    losses = torch.zeros(eval_iters * len(val_dataloader))\n    count = 0\n    for k in range(eval_iters):\n        for src_idx, tgt_idx, src_pad, tgt_pad in val_dataloader:\n            # idx, targets = get_batch(split=split)\n            src_idx, tgt_idx, src_pad, tgt_pad = src_idx.to(device), tgt_idx.to(device), src_pad.to(device), tgt_pad.to(device)\n          \n            logits = model(src_idx, tgt_idx, src_pad, tgt_pad)\n            batch_size, block_size, embeddings_dims = logits.shape\n            logits = logits.view(batch_size*block_size, embeddings_dims) # Total tokens(words) => batch_size * block_size\n            targets = tgt_idx.view(batch_size * block_size)\n            loss = nn.functional.cross_entropy(logits, targets)\n            losses[count] = loss.item()\n            count += 1\n\n    out['val'] = losses.mean()\n    model.train()\n    return out","metadata":{"id":"LH95cJEvcuoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:42.450897Z","iopub.execute_input":"2024-12-30T23:41:42.451139Z","iopub.status.idle":"2024-12-30T23:41:43.142042Z","shell.execute_reply.started":"2024-12-30T23:41:42.451116Z","shell.execute_reply":"2024-12-30T23:41:43.141341Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"#Train the  model\nfrom tqdm import tqdm\nloss_ = torch.zeros(epochs * len(train_dataloader))\nmodel.train()\ncount1 = 0\n# batch_counter = 0\nfor epoch  in tqdm(range(epochs)):\n    eval = True\n    loss_ = torch.zeros(epochs * len(train_dataloader))\n    count1 = 0\n    for src_idx, tgt_idx, src_pad, tgt_pad in train_dataloader:\n\n      # Evaluate and print loss every epoch for a total of 5 val epochs (kinda like cross-val)\n      # is_eval_iter = (batch_counter % eval_iters == 0 and batch_counter > 0)\n      # is_last_batch = (epoch == epochs - 1 and batch_counter == epochs * len(train_dataloader))\n\n      # print(batch_counter)\n      if eval and epoch != 0:\n          # print(batch_counter)\n          # print(is_eval_iter)\n          # print(is_last_batch)\n          eval = False\n          losses = estimate_loss()\n          print(f\"epoch {epoch}: train loss {loss.item():.4f}, val loss {losses['val']:.4f}\")\n\n      else:\n        src_idx, tgt_idx, src_pad, tgt_pad = src_idx.to(device), tgt_idx.to(device), src_pad.to(device), tgt_pad.to(device)\n          \n        # idx, targets = get_batch(split='train')\n        logits = model(src_idx, tgt_idx, src_pad, tgt_pad)\n        batch_size, block_size, embeddings_dims = logits.shape\n        logits = logits.view(batch_size*block_size, embeddings_dims)\n        targets = tgt_idx.view(batch_size * block_size)\n        loss = nn.functional.cross_entropy(logits, targets)\n        # loss_[count1] = loss.item()\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n        # count1 += 1\n        # batch_counter -= 1","metadata":{"id":"nPrSPPu8cuoO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4c863fc2-765d-4fa1-8450-69e3358eedaa","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T23:41:43.142879Z","iopub.execute_input":"2024-12-30T23:41:43.143397Z","iopub.status.idle":"2024-12-31T00:20:53.976987Z","shell.execute_reply.started":"2024-12-30T23:41:43.143371Z","shell.execute_reply":"2024-12-31T00:20:53.976269Z"}},"outputs":[{"name":"stderr","text":" 33%|███▎      | 1/3 [12:34<25:08, 754.42s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 1: train loss 0.0248, val loss 0.0315\n","output_type":"stream"},{"name":"stderr","text":" 67%|██████▋   | 2/3 [25:51<12:59, 779.70s/it]","output_type":"stream"},{"name":"stdout","text":"epoch 2: train loss 0.0147, val loss 0.0153\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3/3 [39:10<00:00, 783.61s/it]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}